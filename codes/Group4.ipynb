{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive') # 코랩에 구글드라이브 연동해서 안에 파일들을 사용할 수 있게끔 해준다"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TcuJLlnYPgpL","executionInfo":{"status":"ok","timestamp":1720156245188,"user_tz":-540,"elapsed":17972,"user":{"displayName":"핑도도도","userId":"04659225726467828001"}},"outputId":"2e4c58dc-68f1-4441-9451-80d64c00bf5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","\n","os.chdir('drive/MyDrive/Multimodal_Fusion_Ratings')\n","print(os.listdir())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wl_x27IuOSpG","executionInfo":{"status":"ok","timestamp":1720156293396,"user_tz":-540,"elapsed":327,"user":{"displayName":"핑도도도","userId":"04659225726467828001"}},"outputId":"6b9bbcd8-0151-4a42-b96e-33dc377d6599"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Multi-Modal_Deep_Learning_for_Credit_Rating_Prediction_Using_Text_and_Numerical_Data_Streams.pdf', 'MultimodalFusionRatings', 'Group4.ipynb']\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ot0SZJlH4na4"},"outputs":[],"source":["# 수집한 데이터 load\n","\n","import pandas as pd\n","data_main=pd.read_excel(\"MultimodalFusionRatings/Data/Artificial_Data.xlsx\")"]},{"cell_type":"code","source":["data_main['Rating']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KTaWMG2qTCM2","executionInfo":{"status":"ok","timestamp":1720156359303,"user_tz":-540,"elapsed":329,"user":{"displayName":"핑도도도","userId":"04659225726467828001"}},"outputId":"12b71f9f-ba3c-478a-d0c0-196d0f62283f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       A+\n","1       BB\n","2       BB\n","3      BBB\n","4       AA\n","      ... \n","95    BBB+\n","96      AA\n","97      BB\n","98     AA+\n","99     BBB\n","Name: Rating, Length: 100, dtype: object"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IAGnKze-4na8"},"outputs":[],"source":["# 구글 코랩에서 진행 예정이라 따로 memory growth를 직접 설정할 필요는 없음.\n","# 진행하면서 memory allocation 문제가 생기면 그때 한번 확인하고 돌려보기\n","\n","# import tensorflow as tf\n","# gpus = tf.config.experimental.list_physical_devices('GPU')\n","# if gpus:\n","#     try:\n","#         # Currently, memory growth needs to be the same across GPUs\n","#         for gpu in gpus:\n","#             tf.config.experimental.set_memory_growth(gpu, True)\n","#         logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","#         print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","#     except RuntimeError as e:\n","#         # Memory growth must be set before GPUs have been initialized\n","#         print(e)\n","# Set multiple gpus\n","# strategy = tf.distribute.MirroredStrategy()"]},{"cell_type":"code","source":["#change of the rating classes to new classes\n","import numpy as np\n","\n","\n","\n","# TODO: 실제 데이터에서는 이부분에 moody's rating은 다르기 때문에,\n","# 딕셔너리를 따로 만들어서 일단 하나로 통합을 하고 변환을 해줘야함\n","# 실제 데이터가 어떤지 받아봐야 확인 가능\n","\n","\n","\n","lbl_first=data_main[\"Rating\"].values # rating을 수정해주기 전 데이터를 보관 (.values 는 np array로 받게해줌)\n","lbl_final=lbl_first.copy() # rating을 새로운 class로 수정 후 데이터\n","\n","# 각 class의 비중을 다소 균등하게 조절하기 위해 신규 class로 묶어주기\n","dict_trans_class={1: ['AAA', 'AA+', 'AA', 'AA-', 'A+'],\n","                  2: ['A'],\n","                  3: ['A-'],\n","                  4: ['BBB+'],\n","                  5: ['BBB'],\n","                  6: ['BBB', 'BB+', 'BB'],\n","                  7: ['BB-', 'B+', 'B'],\n","                  8: ['B-', 'CCC', 'CCC-', 'C', 'D']\n","                  }\n","\n","# 해당하는 기존 class를 신규 class로 변경\n","for class_main_idx in dict_trans_class:\n","  lst_class = dict_trans_class[class_main_idx]\n","  print(lst_class)\n","  for item in lst_class:\n","    lbl_final = np.where(lbl_first == item, class_main_idx, lbl_final)"],"metadata":{"id":"P7pp-0HCSLHs","executionInfo":{"status":"ok","timestamp":1720160366620,"user_tz":-540,"elapsed":367,"user":{"displayName":"핑도도도","userId":"04659225726467828001"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"43ca8a8f-5b0c-4c39-89cf-45019072bc7c"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["['AAA', 'AA+', 'AA', 'AA-', 'A+']\n","['A']\n","['A-']\n","['BBB+']\n","['BBB']\n","['BBB', 'BB+', 'BB']\n","['BB-', 'B+', 'B']\n","['B-', 'CCC', 'CCC-', 'C', 'D']\n"]}]},{"cell_type":"code","source":["lbl_final"],"metadata":{"id":"pxIqhEkSdMLp","executionInfo":{"status":"ok","timestamp":1720160380039,"user_tz":-540,"elapsed":397,"user":{"displayName":"핑도도도","userId":"04659225726467828001"}},"outputId":"f5013605-87d8-4b7e-db5b-f70a960dd087","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 6, 6, 6, 1, 1, 1, 6, 1, 1, 1, 1, 2, 1, 6, 1, 1, 1, 6, 1, 6, 1,\n","       1, 1, 6, 6, 6, 4, 6, 2, 1, 1, 6, 4, 1, 1, 1, 1, 2, 6, 4, 1, 1, 2,\n","       1, 6, 6, 4, 6, 1, 1, 6, 6, 1, 1, 1, 2, 1, 6, 6, 6, 1, 1, 2, 6, 1,\n","       4, 2, 6, 6, 2, 6, 1, 2, 1, 2, 6, 6, 1, 1, 4, 1, 1, 1, 2, 4, 1, 2,\n","       4, 1, 1, 1, 1, 1, 4, 4, 1, 6, 1, 6], dtype=object)"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["# 신규 class 별 숫자를 확인\n","lbl_final_rest = lbl_final.copy()\n","uni_class = np.unique(lbl_final)\n","print(uni_class)\n","for idx,item in enumerate(uni_class):\n","    lbl_final_rest=np.where(lbl_final == item, idx, lbl_final_rest)\n","print(lbl_final_rest)\n","unique, counts = np.unique(lbl_final_rest, return_counts=True)\n","print(np.asarray((unique, counts)).T)"],"metadata":{"id":"hwP__A4RdJ9_","executionInfo":{"status":"ok","timestamp":1720160390658,"user_tz":-540,"elapsed":346,"user":{"displayName":"핑도도도","userId":"04659225726467828001"}},"outputId":"947704d4-e01a-44eb-beaf-d8592e421aa6","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 2 4 6]\n","[[0 49]\n"," [1 12]\n"," [2 10]\n"," [3 29]]\n"]}]},{"cell_type":"code","source":["# 더 진행하기 전에 기존 데이터 카피를 만들어주고, text를 토큰으로 받기\n","data_pre = data_main.copy()\n","data_token = data_pre[\"string_values\"].values # type = np array"],"metadata":{"id":"tgv2DWCvT6Lq","executionInfo":{"status":"ok","timestamp":1720162527675,"user_tz":-540,"elapsed":389,"user":{"displayName":"핑도도도","userId":"04659225726467828001"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# text preprocessing\n","\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('words')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X2Xsh3gJjTLQ","executionInfo":{"status":"ok","timestamp":1720162861326,"user_tz":-540,"elapsed":2674,"user":{"displayName":"핑도도도","userId":"04659225726467828001"}},"outputId":"b9fb1d41-d55e-4696-daf2-e37406d8b642"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/words.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["!pip install clean-text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6RJWHbZhsx-u","executionInfo":{"status":"ok","timestamp":1720162935428,"user_tz":-540,"elapsed":8770,"user":{"displayName":"핑도도도","userId":"04659225726467828001"}},"outputId":"8c8a9cc5-80e0-44ec-d503-b0ea566222c8"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting clean-text\n","  Downloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n","Collecting emoji<2.0.0,>=1.0.0 (from clean-text)\n","  Downloading emoji-1.7.0.tar.gz (175 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting ftfy<7.0,>=6.0 (from clean-text)\n","  Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.13)\n","Building wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171034 sha256=d75ef3b77eca04388a3a3dd201b9b65dad70102f8421f778d104309778812c5a\n","  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n","Successfully built emoji\n","Installing collected packages: emoji, ftfy, clean-text\n","Successfully installed clean-text-0.6.0 emoji-1.7.0 ftfy-6.2.0\n"]}]},{"cell_type":"code","source":["\n","\n","import numpy as np\n","import pandas as pd\n","import os\n","import re\n","from sklearn.feature_extraction.text import CountVectorizer\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","from nltk.stem import WordNetLemmatizer\n","from cleantext import clean"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1DRnF5pqrTWm","executionInfo":{"status":"ok","timestamp":1720162935908,"user_tz":-540,"elapsed":486,"user":{"displayName":"핑도도도","userId":"04659225726467828001"}},"outputId":"6d4accf6-23a5-4087-cc52-2ae7a2f87ec0"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:root:Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"]}]},{"cell_type":"code","source":["# get lemmatized review\n","def get_lemmatized_text(corpus):\n","    lemmatizer = WordNetLemmatizer()\n","    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n","\n","# get stemmed review\n","def get_stemmed_text(corpus):\n","    stemmer = PorterStemmer()\n","    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]"],"metadata":{"id":"XR_TPAlistJk","executionInfo":{"status":"ok","timestamp":1720163144217,"user_tz":-540,"elapsed":364,"user":{"displayName":"핑도도도","userId":"04659225726467828001"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["# remove all stopwords in english review\n","def remove_stop_words(corpus):\n","    english_stop_words = stopwords.words('english')\n","    removed_stop_words = []\n","    for review in corpus:\n","        removed_stop_words.append(\n","            ' '.join([word for word in review.split()\n","                      if word not in english_stop_words])\n","        )\n","    return removed_stop_words"],"metadata":{"id":"z5zCbUk8tAmV","executionInfo":{"status":"ok","timestamp":1720163451315,"user_tz":-540,"elapsed":446,"user":{"displayName":"핑도도도","userId":"04659225726467828001"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["# # preprocess review\n","def preprocess_txt(reviews):\n","    REPLACE_NO_SPACE = re.compile(\"(\\.)|(!)\\;)|(\\:)|(\\|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n","    REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n","    NO_SPACE = \"\"\n","    SPACE = \" \"\n","    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, reviews.lower())]\n","    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n","    return reviews"],"metadata":{"id":"glXmJdKWuz4m","executionInfo":{"status":"ok","timestamp":1720163990455,"user_tz":-540,"elapsed":407,"user":{"displayName":"핑도도도","userId":"04659225726467828001"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["# clean review by cleantext libaray\n","def clean_text(sent):\n","  clean_sent=clean(sent,\n","      fix_unicode=True,               # fix various unicode errors\n","      to_ascii=True,                  # transliterate to closest ASCII representation\n","      lower=True,                     # lowercase text\n","      no_line_breaks=False,           # fully strip line breaks as opposed to only normalizing them\n","      no_urls=True,                  # replace all URLs with a special token\n","      no_emails=True,                # replace all email addresses with a special token\n","      no_phone_numbers=True,         # replace all phone numbers with a special token\n","      no_numbers=False,               # replace all numbers with a special token\n","      no_digits=True,                # replace all digits with a special token\n","      no_currency_symbols=True,      # replace all currency symbols with a special token\n","      no_punct=True,                 # remove punctuations\n","      replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n","      replace_with_url=\"\",\n","      replace_with_email=\"\",\n","      replace_with_phone_number=\"\",\n","      replace_with_number=\"\",\n","      replace_with_digit=\"0\",\n","      replace_with_currency_symbol=\"\",\n","      lang=\"en\" )\n","  return clean_sent"],"metadata":{"id":"dx97LHekwq3d","executionInfo":{"status":"ok","timestamp":1720164020359,"user_tz":-540,"elapsed":362,"user":{"displayName":"핑도도도","userId":"04659225726467828001"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["# 위에서 만든 전처리 함수들을 텍스트에 적용\n","data_pre[\"string_values\"]=data_pre[\"string_values\"].apply(lambda x:clean_text(x))\n","data_pre[\"string_values\"]=data_pre[\"string_values\"].apply(lambda x:preprocess_txt(x))\n","data_pre[\"string_values\"]=data_pre[\"string_values\"].apply(lambda x:remove_stop_words(x))\n","data_pre[\"string_values\"]=data_pre[\"string_values\"].apply(lambda x:get_stemmed_text(x))"],"metadata":{"id":"RyhacTstw-1G","executionInfo":{"status":"ok","timestamp":1720164280232,"user_tz":-540,"elapsed":363,"user":{"displayName":"핑도도도","userId":"04659225726467828001"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["#############################Tokenization\n","\n","import matplotlib.pyplot as plt\n","text = data_token # data_token 은 string_values 열의 값을 np array로 받은 것\n","data_token_re=data_token.copy()\n","from keras.preprocessing.text import Tokenizer\n","MAX_NB_WORDS=500000\n","tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n","tokenizer.fit_on_texts(data_token_re)\n","data_seq = tokenizer.texts_to_sequences(data_token_re)\n","vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","maxlen = 5000\n","data_seq_pad = pad_sequences(data_seq, padding='pre', maxlen=maxlen)"],"metadata":{"id":"yBNJLpTzx-R7","executionInfo":{"status":"ok","timestamp":1720167459559,"user_tz":-540,"elapsed":358,"user":{"displayName":"핑도도도","userId":"04659225726467828001"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["###############################Numeric part\n","from tensorflow.keras.utils import  to_categorical\n","lbl_binary = to_categorical(lbl_final_rest).astype(int)\n","# 4:101:mareket, 102:110:bond info, 111:157:finRatio\n","d1=dum\n","d2=data[list(data.iloc[:,4:101])]\n","d3=data[list(data.iloc[:,102:110])]\n","d4=data[list(data.iloc[:,111:157])]\n","\n","\n","\n","from sklearn.preprocessing import MinMaxScaler\n","data_meta_normal1=d1.copy()\n","data_meta_normal2=d2.copy()\n","data_meta_normal3=d3.copy()\n","data_meta_normal4=d4.copy()\n","\n","\n","sce=MinMaxScaler()\n","for item_col in data_meta_normal2.columns:\n","    data_meta_normal2[item_col]=sce.fit_transform(d2[item_col].values.reshape(-1,1))\n","\n","for item_col in data_meta_normal3.columns:\n","    data_meta_normal3[item_col]=sce.fit_transform(d3[item_col].values.reshape(-1,1))\n","\n","for item_col in data_meta_normal4.columns:\n","    data_meta_normal4[item_col]=sce.fit_transform(d4[item_col].values.reshape(-1,1))\n","\n","\n","\n","\n","from tensorflow.keras.utils import to_categorical\n","lbl_binary=to_categorical(lbl_final_rest).astype(int)"],"metadata":{"id":"J01K_3i94Ncs"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}